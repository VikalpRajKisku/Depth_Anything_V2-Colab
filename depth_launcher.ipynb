{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Depth Anything V2 - Pro Video Processor\n",
        "\n",
        "**Robust. Hardware-Agnostic. Advanced.**\n",
        "\n",
        "This notebook provides a complete pipeline for monocular depth estimation on videos, featuring:\n",
        "- **Dual Modes**: Standard Relative Depth (Visuals) & Metric Depth (Measurements).\n",
        "- **Hardware Smart**: Automatically uses GPU (FP16) for speed or CPU (FP32) for compatibility.\n",
        "- **3D Snapshots**: Export high-quality 3D Point Clouds (.ply) from any frame.\n",
        "- **Robust Engine**: Flicker reduction, high-quality FFmpeg encoding, and memory safety."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 1. Install Dependencies\n",
        "# @markdown Run this cell once to setup the environment.\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_dependencies():\n",
        "    print(\"‚öôÔ∏è Installing system dependencies... (This may take 1-2 minutes)\")\n",
        "    packages = [\n",
        "        \"git+https://github.com/huggingface/transformers.git\",\n",
        "        \"accelerate\",\n",
        "        \"opencv-python\",\n",
        "        \"yt-dlp\",\n",
        "        \"torch\",\n",
        "        \"pillow\",\n",
        "        \"numpy\"\n",
        "    ]\n",
        "    command = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages\n",
        "    try:\n",
        "        subprocess.check_call(command)\n",
        "        print(\"‚úÖ Dependencies installed successfully.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Installation failed: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    install_dependencies()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb1765f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 2. Initialize Depth Engine\n",
        "# @markdown This cell defines the core processing logic. Run it to load the engine.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import subprocess\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "import yt_dlp\n",
        "\n",
        "# --- Logging Setup (Restored Legacy Style) ---\n",
        "def log(msg):\n",
        "    print(msg)\n",
        "\n",
        "class DepthVideoEngine:\n",
        "    def __init__(self, model_type=\"Relative\", model_size=\"small\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_type: 'Relative' (Visuals) or 'Metric' (Measurements).\n",
        "            model_size: 'small', 'base', 'large' (Only for Relative).\n",
        "        \"\"\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_type = model_type\n",
        "        \n",
        "        # Select Checkpoint\n",
        "        if model_type == \"Metric\":\n",
        "            self.checkpoint = \"depth-anything/Depth-Anything-V2-Metric-Hypersim-Small-hf\"\n",
        "            log(f\"üìè Mode: Metric Depth ({self.checkpoint})\")\n",
        "        else:\n",
        "            self.checkpoint = f\"depth-anything/Depth-Anything-V2-{model_size.title()}-hf\"\n",
        "            log(f\"üé® Mode: Relative Depth ({self.checkpoint})\")\n",
        "\n",
        "        log(f\"üöÄ Acceleration: {self.device.upper()}\")\n",
        "        \n",
        "        try:\n",
        "            self.processor = AutoImageProcessor.from_pretrained(self.checkpoint)\n",
        "            self.model = AutoModelForDepthEstimation.from_pretrained(self.checkpoint).to(self.device)\n",
        "            log(\"‚úÖ Model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            log(f\"‚ùå Model load failed: {e}\")\n",
        "            raise e\n",
        "\n",
        "    def process_video(self, video_path, output_resolution=\"480p\", smooth_window=0, snapshot_time=None):\n",
        "        if not os.path.exists(video_path):\n",
        "            log(f\"‚ùå File not found: {video_path}\")\n",
        "            return None, None\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        # Resolution Logic\n",
        "        if output_resolution == \"Native\":\n",
        "            target_h, target_w = orig_h, orig_w\n",
        "        else:\n",
        "            target_p = int(output_resolution.replace(\"p\", \"\"))\n",
        "            if orig_h > target_p:\n",
        "                scale = target_p / orig_h\n",
        "                target_h = target_p\n",
        "                target_w = int(orig_w * scale)\n",
        "                if target_w % 2 != 0: target_w -= 1\n",
        "            else:\n",
        "                target_h, target_w = orig_h, orig_w\n",
        "\n",
        "        log(f\"üé¨ Processing: {orig_w}x{orig_h} -> Resizing to: {target_w}x{target_h} @ {fps}fps\")\n",
        "\n",
        "        # Writers\n",
        "        temp_out = \"temp_depth.avi\"\n",
        "        out = cv2.VideoWriter(temp_out, cv2.VideoWriter_fourcc(*'MJPG'), fps, (target_w, target_h))\n",
        "        \n",
        "        # Optimization: Only use buffer if smoothing is requested\n",
        "        use_smoothing = smooth_window > 1\n",
        "        if use_smoothing:\n",
        "            buffer = deque(maxlen=smooth_window)\n",
        "        \n",
        "        snapshot_frame_idx = int(snapshot_time * fps) if snapshot_time is not None else -1\n",
        "        snapshot_ply_path = None\n",
        "\n",
        "        frame_idx = 0\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret: break\n",
        "\n",
        "                # Resize Input (Critical Speedup)\n",
        "                if (target_w, target_h) != (orig_w, orig_h):\n",
        "                    frame_in = cv2.resize(frame, (target_w, target_h), interpolation=cv2.INTER_AREA)\n",
        "                else:\n",
        "                    frame_in = frame\n",
        "\n",
        "                # Inference\n",
        "                inputs = self.processor(images=cv2.cvtColor(frame_in, cv2.COLOR_BGR2RGB), return_tensors=\"pt\").to(self.device)\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    if self.device == \"cuda\":\n",
        "                        with torch.cuda.amp.autocast():\n",
        "                            outputs = self.model(**inputs)\n",
        "                            depth = outputs.predicted_depth\n",
        "                    else:\n",
        "                        outputs = self.model(**inputs)\n",
        "                        depth = outputs.predicted_depth\n",
        "\n",
        "                # Interpolate\n",
        "                depth = F.interpolate(depth.unsqueeze(1), size=(target_h, target_w), mode=\"bicubic\", align_corners=False).squeeze().cpu().numpy()\n",
        "\n",
        "                # 3D Snapshot\n",
        "                if frame_idx == snapshot_frame_idx:\n",
        "                    log(f\"üì∏ Capturing 3D Snapshot at {snapshot_time}s...\")\n",
        "                    snapshot_ply_path = self.save_ply(frame_in, depth, f\"snapshot_{frame_idx}.ply\")\n",
        "\n",
        "                # Smoothing vs Raw\n",
        "                if use_smoothing:\n",
        "                    buffer.append(depth)\n",
        "                    avg_depth = np.mean(buffer, axis=0)\n",
        "                    final_depth = avg_depth\n",
        "                else:\n",
        "                    final_depth = depth\n",
        "\n",
        "                # Normalize & Colorize\n",
        "                d_min, d_max = final_depth.min(), final_depth.max()\n",
        "                if d_max - d_min > 1e-6:\n",
        "                    depth_norm = (final_depth - d_min) / (d_max - d_min)\n",
        "                else:\n",
        "                    depth_norm = np.zeros_like(final_depth)\n",
        "                \n",
        "                depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
        "                heatmap = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
        "\n",
        "                out.write(heatmap)\n",
        "                frame_idx += 1\n",
        "                \n",
        "                if frame_idx % 50 == 0:\n",
        "                    log(f\"‚è≥ Processed {frame_idx} / {total_frames or '?'}\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            log(\"‚ö†Ô∏è Interrupted. Saving partial result...\")\n",
        "        finally:\n",
        "            cap.release()\n",
        "            out.release()\n",
        "\n",
        "        # Encode\n",
        "        log(\"‚öôÔ∏è Encoding final MP4...\")\n",
        "        final_mp4 = f\"depth_output_{output_resolution}.mp4\"\n",
        "        self.encode_ffmpeg(temp_out, final_mp4)\n",
        "        return final_mp4, snapshot_ply_path\n",
        "\n",
        "    def save_ply(self, image, depth, filename):\n",
        "        # Simple PLY writer to avoid heavy dependencies\n",
        "        height, width = depth.shape\n",
        "        # Create grid\n",
        "        x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
        "        x = x.flatten()\n",
        "        y = y.flatten()\n",
        "        z = depth.flatten()\n",
        "        \n",
        "        # Color\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        r = image[:,:,0].flatten()\n",
        "        g = image[:,:,1].flatten()\n",
        "        b = image[:,:,2].flatten()\n",
        "        \n",
        "        # Filter zeros or far points if needed, but keeping simple for now\n",
        "        points = np.stack((x, y, z, r, g, b), axis=1)\n",
        "        \n",
        "        header = f\"\"\"ply\n",
        "format ascii 1.0\n",
        "element vertex {len(points)}\n",
        "property float x\n",
        "property float y\n",
        "property float z\n",
        "property uchar red\n",
        "property uchar green\n",
        "property uchar blue\n",
        "end_header\n",
        "\"\"\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(header)\n",
        "            np.savetxt(f, points, fmt=\"%f %f %f %d %d %d\")\n",
        "        \n",
        "        log(f\"üíæ Saved 3D Snapshot: {filename}\")\n",
        "        return filename\n",
        "\n",
        "    def encode_ffmpeg(self, input_file, output_file):\n",
        "        if os.path.exists(output_file): os.remove(output_file)\n",
        "        cmd = [\n",
        "            \"ffmpeg\", \"-y\", \"-i\", input_file,\n",
        "            \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\",\n",
        "            \"-crf\", \"23\", \"-preset\", \"fast\",\n",
        "            \"-loglevel\", \"error\", output_file\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "        if os.path.exists(input_file): os.remove(input_file)\n",
        "\n",
        "    def download_video(self, url):\n",
        "        filename = \"input_video.mp4\"\n",
        "        if os.path.exists(filename): os.remove(filename)\n",
        "        \n",
        "        ydl_opts = {'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]', 'outtmpl': filename, 'quiet': True}\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([url])\n",
        "            return filename\n",
        "        except:\n",
        "            # Fallback direct\n",
        "            import urllib.request\n",
        "            urllib.request.urlretrieve(url, filename)\n",
        "            return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873a62c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 3. Run Dashboard\n",
        "# @markdown Configure your settings and run processing.\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import display, Video\n",
        "\n",
        "# --- Parameters ---\n",
        "VIDEO_SOURCE = \"https://videos.pexels.com/video-files/30982132/13244096_1080_1920_30fps.mp4\" # @param {type:\"string\"}\n",
        "MODEL_TYPE = \"Relative\" # @param [\"Relative\", \"Metric\"]\n",
        "MODEL_SIZE = \"small\" # @param [\"small\", \"base\", \"large\"]\n",
        "RESOLUTION = \"480p\" # @param [\"Native\", \"720p\", \"480p\", \"360p\"]\n",
        "SMOOTHING = 0 # @param {type:\"slider\", min:0, max:10, step:1}\n",
        "SNAPSHOT_TIME = 2.5 # @param {type:\"number\"}\n",
        "GENERATE_SNAPSHOT = True # @param {type:\"boolean\"}\n",
        "\n",
        "def run_dashboard():\n",
        "    print(\"üîß Initializing Engine...\")\n",
        "    engine = DepthVideoEngine(model_type=MODEL_TYPE, model_size=MODEL_SIZE)\n",
        "    \n",
        "    # Get Video\n",
        "    if VIDEO_SOURCE.startswith(\"http\"):\n",
        "        print(\"‚¨áÔ∏è Downloading video...\")\n",
        "        video_path = engine.download_video(VIDEO_SOURCE)\n",
        "    else:\n",
        "        video_path = VIDEO_SOURCE\n",
        "        \n",
        "    if not os.path.exists(video_path):\n",
        "        print(\"‚ùå Video not found. Please upload or check URL.\")\n",
        "        return\n",
        "\n",
        "    # Preview Input\n",
        "    print(f\"\\nüé¨ Input Preview: {video_path}\")\n",
        "    display(Video(video_path, embed=True, width=400))\n",
        "\n",
        "    # Process\n",
        "    print(\"\\n‚öôÔ∏è Processing...\")\n",
        "    snap_t = SNAPSHOT_TIME if GENERATE_SNAPSHOT else None\n",
        "    final_video, ply_file = engine.process_video(video_path, RESOLUTION, smooth_window=SMOOTHING, snapshot_time=snap_t)\n",
        "    \n",
        "    # Display Output\n",
        "    if final_video:\n",
        "        print(f\"\\n‚ú® Video Ready: {final_video}\")\n",
        "        print(\"üé¨ Output Preview:\")\n",
        "        display(Video(final_video, embed=True, width=400))\n",
        "        \n",
        "        print(\"‚¨áÔ∏è Downloading result...\")\n",
        "        files.download(final_video)\n",
        "        \n",
        "    if ply_file:\n",
        "        print(f\"\\nüßä 3D Snapshot Ready: {ply_file}\")\n",
        "        files.download(ply_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_dashboard()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
