{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Depth Anything V2 - Pro Video Processor\n",
        "\n",
        "**Robust. Hardware-Agnostic. Advanced.**\n",
        "\n",
        "This notebook provides a complete pipeline for monocular depth estimation on videos, featuring:\n",
        "- **Dual Modes**: Standard Relative Depth (Visuals) & Metric Depth (Measurements).\n",
        "- **Hardware Smart**: Automatically uses GPU (FP16) for speed or CPU (FP32) for compatibility.\n",
        "- **3D Snapshots**: Export high-quality 3D Point Clouds (.ply) from any frame.\n",
        "- **Robust Engine**: Flicker reduction, high-quality FFmpeg encoding, and memory safety."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 1. Install Dependencies\n",
        "# @markdown Run this cell once to setup the environment.\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_dependencies():\n",
        "    print(\"‚öôÔ∏è Installing system dependencies... (This may take 1-2 minutes)\")\n",
        "    packages = [\n",
        "        \"git+https://github.com/huggingface/transformers.git\",\n",
        "        \"accelerate\",\n",
        "        \"opencv-python\",\n",
        "        \"yt-dlp\",\n",
        "        \"torch\",\n",
        "        \"pillow\",\n",
        "        \"numpy\"\n",
        "    ]\n",
        "    command = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages\n",
        "    try:\n",
        "        subprocess.check_call(command)\n",
        "        print(\"‚úÖ Dependencies installed successfully.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Installation failed: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    install_dependencies()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 2. Initialize Depth Engine\n",
        "# @markdown This cell defines the core processing logic. Run it to load the engine.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import subprocess\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "import yt_dlp\n",
        "\n",
        "# --- Logging Setup ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%H:%M:%S')\n",
        "logger = logging.getLogger(\"DepthPro\")\n",
        "\n",
        "class DepthVideoEngine:\n",
        "    def __init__(self, model_type=\"Relative\", model_size=\"small\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_type: 'Relative' (Visuals) or 'Metric' (Measurements).\n",
        "            model_size: 'small', 'base', 'large' (Only for Relative).\n",
        "        \"\"\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_type = model_type\n",
        "        \n",
        "        # Select Checkpoint\n",
        "        if model_type == \"Metric\":\n",
        "            # Metric models: depth-anything/Depth-Anything-V2-Metric-vkitti-hf (example)\n",
        "            # Using a general purpose metric model if available, or falling back to a robust relative one if specific metric ones are tricky to load via AutoModel without specific config.\n",
        "            # For V2 Metric, we use the official HF repo structure.\n",
        "            self.checkpoint = \"depth-anything/Depth-Anything-V2-Metric-Hypersim-Small-hf\" # Example metric model\n",
        "            logger.info(f\"üìè Mode: Metric Depth ({self.checkpoint})\")\n",
        "        else:\n",
        "            self.checkpoint = f\"depth-anything/Depth-Anything-V2-{model_size.title()}-hf\"\n",
        "            logger.info(f\"üé® Mode: Relative Depth ({self.checkpoint})\")\n",
        "\n",
        "        logger.info(f\"üöÄ Hardware: {self.device.upper()}\")\n",
        "        \n",
        "        try:\n",
        "            self.processor = AutoImageProcessor.from_pretrained(self.checkpoint)\n",
        "            self.model = AutoModelForDepthEstimation.from_pretrained(self.checkpoint).to(self.device)\n",
        "            logger.info(\"‚úÖ Model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Model load failed: {e}\")\n",
        "            raise e\n",
        "\n",
        "    def process_video(self, video_path, output_resolution=\"480p\", smooth_window=3, snapshot_time=None):\n",
        "        if not os.path.exists(video_path):\n",
        "            logger.error(\"Video file not found.\")\n",
        "            return None, None\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        # Resolution Logic\n",
        "        if output_resolution == \"Native\":\n",
        "            target_h, target_w = orig_h, orig_w\n",
        "        else:\n",
        "            target_p = int(output_resolution.replace(\"p\", \"\"))\n",
        "            scale = target_p / orig_h\n",
        "            target_h = target_p\n",
        "            target_w = int(orig_w * scale)\n",
        "            if target_w % 2 != 0: target_w -= 1\n",
        "\n",
        "        logger.info(f\"üé¨ Processing: {orig_w}x{orig_h} -> {target_w}x{target_h} @ {fps}fps\")\n",
        "\n",
        "        # Writers\n",
        "        temp_out = \"temp_depth.avi\"\n",
        "        out = cv2.VideoWriter(temp_out, cv2.VideoWriter_fourcc(*'MJPG'), fps, (target_w, target_h))\n",
        "        \n",
        "        buffer = deque(maxlen=smooth_window)\n",
        "        snapshot_frame_idx = int(snapshot_time * fps) if snapshot_time is not None else -1\n",
        "        snapshot_ply_path = None\n",
        "\n",
        "        frame_idx = 0\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret: break\n",
        "\n",
        "                # Resize\n",
        "                if (target_w, target_h) != (orig_w, orig_h):\n",
        "                    frame_in = cv2.resize(frame, (target_w, target_h), interpolation=cv2.INTER_AREA)\n",
        "                else:\n",
        "                    frame_in = frame\n",
        "\n",
        "                # Inference (FP16 on CUDA, FP32 on CPU)\n",
        "                inputs = self.processor(images=cv2.cvtColor(frame_in, cv2.COLOR_BGR2RGB), return_tensors=\"pt\").to(self.device)\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    if self.device == \"cuda\":\n",
        "                        with torch.cuda.amp.autocast():\n",
        "                            outputs = self.model(**inputs)\n",
        "                            depth = outputs.predicted_depth\n",
        "                    else:\n",
        "                        outputs = self.model(**inputs)\n",
        "                        depth = outputs.predicted_depth\n",
        "\n",
        "                # Interpolate\n",
        "                depth = F.interpolate(depth.unsqueeze(1), size=(target_h, target_w), mode=\"bicubic\", align_corners=False).squeeze().cpu().numpy()\n",
        "\n",
        "                # 3D Snapshot Logic\n",
        "                if frame_idx == snapshot_frame_idx:\n",
        "                    logger.info(f\"üì∏ Capturing 3D Snapshot at {snapshot_time}s...\")\n",
        "                    snapshot_ply_path = self.save_ply(frame_in, depth, f\"snapshot_{frame_idx}.ply\")\n",
        "\n",
        "                # Smoothing\n",
        "                buffer.append(depth)\n",
        "                avg_depth = np.mean(buffer, axis=0)\n",
        "\n",
        "                # Visualization\n",
        "                if self.model_type == \"Metric\":\n",
        "                    # For metric, we just normalize for visualization, but keep values for PLY if needed\n",
        "                    depth_vis = (avg_depth - avg_depth.min()) / (avg_depth.max() - avg_depth.min() + 1e-6)\n",
        "                    depth_uint8 = (depth_vis * 255).astype(np.uint8)\n",
        "                    heatmap = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
        "                else:\n",
        "                    depth_vis = (avg_depth - avg_depth.min()) / (avg_depth.max() - avg_depth.min() + 1e-6)\n",
        "                    depth_uint8 = (depth_vis * 255).astype(np.uint8)\n",
        "                    heatmap = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
        "\n",
        "                out.write(heatmap)\n",
        "                frame_idx += 1\n",
        "                if frame_idx % 50 == 0: logger.info(f\"‚è≥ Processed {frame_idx}/{total_frames}\")\n",
        "\n",
        "        finally:\n",
        "            cap.release()\n",
        "            out.release()\n",
        "\n",
        "        # Encode\n",
        "        final_mp4 = f\"depth_output_{output_resolution}.mp4\"\n",
        "        self.encode_ffmpeg(temp_out, final_mp4)\n",
        "        return final_mp4, snapshot_ply_path\n",
        "\n",
        "    def save_ply(self, image, depth, filename):\n",
        "        # Simple PLY writer to avoid heavy dependencies\n",
        "        height, width = depth.shape\n",
        "        # Create grid\n",
        "        x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
        "        x = x.flatten()\n",
        "        y = y.flatten()\n",
        "        z = depth.flatten()\n",
        "        \n",
        "        # Color\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        r = image[:,:,0].flatten()\n",
        "        g = image[:,:,1].flatten()\n",
        "        b = image[:,:,2].flatten()\n",
        "        \n",
        "        # Filter zeros or far points if needed, but keeping simple for now\n",
        "        points = np.stack((x, y, z, r, g, b), axis=1)\n",
        "        \n",
        "        header = f\"\"\"ply\n",
        "format ascii 1.0\n",
        "element vertex {len(points)}\n",
        "property float x\n",
        "property float y\n",
        "property float z\n",
        "property uchar red\n",
        "property uchar green\n",
        "property uchar blue\n",
        "end_header\n",
        "\"\"\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(header)\n",
        "            np.savetxt(f, points, fmt=\"%f %f %f %d %d %d\")\n",
        "        \n",
        "        logger.info(f\"üíæ Saved 3D Snapshot: {filename}\")\n",
        "        return filename\n",
        "\n",
        "    def encode_ffmpeg(self, input_file, output_file):\n",
        "        if os.path.exists(output_file): os.remove(output_file)\n",
        "        cmd = [\n",
        "            \"ffmpeg\", \"-y\", \"-i\", input_file,\n",
        "            \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\",\n",
        "            \"-crf\", \"23\", \"-preset\", \"fast\",\n",
        "            \"-loglevel\", \"error\", output_file\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "        if os.path.exists(input_file): os.remove(input_file)\n",
        "\n",
        "    def download_video(self, url):\n",
        "        filename = \"input_video.mp4\"\n",
        "        if os.path.exists(filename): os.remove(filename)\n",
        "        \n",
        "        ydl_opts = {'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]', 'outtmpl': filename, 'quiet': True}\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([url])\n",
        "            return filename\n",
        "        except:\n",
        "            # Fallback direct\n",
        "            import urllib.request\n",
        "            urllib.request.urlretrieve(url, filename)\n",
        "            return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0656858",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 3. Run Dashboard\n",
        "# @markdown Configure your settings and run processing.\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import display, Video\n",
        "import os\n",
        "\n",
        "# --- Parameters ---\n",
        "VIDEO_SOURCE = \"https://videos.pexels.com/video-files/30982132/13244096_1080_1920_30fps.mp4\" # @param {type:\"string\"}\n",
        "USE_UPLOAD = False # @param {type:\"boolean\"}\n",
        "MODEL_TYPE = \"Relative\" # @param [\"Relative\", \"Metric\"]\n",
        "MODEL_SIZE = \"small\" # @param [\"small\", \"base\", \"large\"]\n",
        "RESOLUTION = \"480p\" # @param [\"Native\", \"720p\", \"480p\", \"360p\"]\n",
        "SNAPSHOT_TIME = 2.5 # @param {type:\"number\"}\n",
        "GENERATE_SNAPSHOT = True # @param {type:\"boolean\"}\n",
        "\n",
        "def run_dashboard():\n",
        "    print(\"üîß Initializing Engine...\")\n",
        "    engine = DepthVideoEngine(model_type=MODEL_TYPE, model_size=MODEL_SIZE)\n",
        "    \n",
        "    # Get Video\n",
        "    video_path = None\n",
        "    if USE_UPLOAD:\n",
        "        print(\"‚¨ÜÔ∏è Uploading video...\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            video_path = list(uploaded.keys())[0]\n",
        "        else:\n",
        "            print(\"‚ùå No file uploaded.\")\n",
        "            return\n",
        "    elif VIDEO_SOURCE.startswith(\"http\"):\n",
        "        print(\"‚¨áÔ∏è Downloading video...\")\n",
        "        video_path = engine.download_video(VIDEO_SOURCE)\n",
        "    else:\n",
        "        video_path = VIDEO_SOURCE\n",
        "        \n",
        "    if not video_path or not os.path.exists(video_path):\n",
        "        print(\"‚ùå Video not found. Please upload or check URL.\")\n",
        "        return\n",
        "\n",
        "    # Preview Input\n",
        "    print(f\"\\nüé¨ Input Preview: {video_path}\")\n",
        "    display(Video(video_path, embed=True, width=400))\n",
        "\n",
        "    # Process\n",
        "    print(\"\\n‚öôÔ∏è Processing...\")\n",
        "    snap_t = SNAPSHOT_TIME if GENERATE_SNAPSHOT else None\n",
        "    final_video, ply_file = engine.process_video(video_path, RESOLUTION, snapshot_time=snap_t)\n",
        "    \n",
        "    # Display Output\n",
        "    if final_video:\n",
        "        print(f\"\\n‚ú® Video Ready: {final_video}\")\n",
        "        print(\"üé¨ Output Preview:\")\n",
        "        display(Video(final_video, embed=True, width=400))\n",
        "        \n",
        "        print(\"‚¨áÔ∏è Downloading result...\")\n",
        "        files.download(final_video)\n",
        "        \n",
        "    if ply_file:\n",
        "        print(f\"\\nüßä 3D Snapshot Ready: {ply_file}\")\n",
        "        files.download(ply_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_dashboard()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
